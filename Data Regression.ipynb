{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from ast import literal_eval\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from matplotlib.pylab import plt #load plot library\n",
    "# indicate the output of plotting function is printed to the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "data = pd.read_hdf('random_forest.h5')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['zip5'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['datetime'].dt.year < 2019]\n",
    "data = data.drop(['x', 'y', 'any_impute_col', 'impute_row', 'datetime'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data to training and validation (based on percentage)\n",
    "\n",
    "end_ind = int(0.7*data.shape[0])\n",
    "trainData, testData = data.loc[0:end_ind,:], data.loc[end_ind+1:data.shape[0],:]\n",
    "print(trainData.shape, testData.shape)\n",
    "\n",
    "X_train = trainData.drop([\"impact_score\"], axis = 1)\n",
    "X_test = testData.drop([\"impact_score\"], axis = 1)\n",
    "\n",
    "Y_train = trainData[\"impact_score\"]\n",
    "Y_test = testData[\"impact_score\"]\n",
    "print('train data: ', X_train.shape, Y_train.shape, '\\ntest data: ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train.values, Y_train.values)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred_MLR_ori = regr.predict(X_test.values)\n",
    "\n",
    "# The coefficients\n",
    "#print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "\n",
    "y_pred_MLR = y_pred_MLR_ori.flatten()\n",
    "\n",
    "# Clipping values\n",
    "y_pred_MLR[y_pred_MLR<-1] = 0\n",
    "y_pred_MLR[y_pred_MLR>35] = 35\n",
    "\n",
    "\n",
    "print('MLR Error: %.2f'\n",
    "      % mean_squared_error(Y_test.values, y_pred_MLR))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(Y_test.values, y_pred_MLR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression modeling - Parameter Tuning: n_est\n",
    "n_est = 40 #The number of trees in the forest.\n",
    "max_d = 10 #Max depth of the tree\n",
    "min_samples = 100 #The minimum number of samples required to be at a leaf node. \n",
    "\n",
    "n_est_dict_y_e = {}\n",
    "n_est_dict_mse_e = {}\n",
    "\n",
    "for n_est in range(40,220,40):\n",
    "    m1 = RandomForestRegressor(n_estimators = n_est, max_depth = max_d, min_samples_leaf = min_samples)\n",
    "    m1.fit(X_train,Y_train)\n",
    "    y_pred_RF = m1.predict(X_test)\n",
    "    n_est_dict_mse_e[n_est] = metrics.mean_squared_error(Y_test, y_pred_RF)\n",
    "    n_est_dict_y_e[n_est] = y_pred_RF\n",
    "    print(\"RF Error:\", metrics.mean_squared_error(Y_test, y_pred_RF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression modeling - Parameter Tuning: max_d\n",
    "n_est = 40 #The number of trees in the forest.\n",
    "max_d = 10 #Max depth of the tree\n",
    "min_samples = 100 #The minimum number of samples required to be at a leaf node. \n",
    "\n",
    "n_est_dict_y_d = {}\n",
    "n_est_dict_mse_d = {}\n",
    "\n",
    "for max_d in range(10,22,2):\n",
    "    m1 = RandomForestRegressor(n_estimators = n_est, max_depth = max_d, min_samples_leaf = min_samples)\n",
    "    m1.fit(X_train,Y_train)\n",
    "    y_pred_RF = m1.predict(X_test)\n",
    "    n_est_dict_mse_d[max_d] = metrics.mean_squared_error(Y_test, y_pred_RF)\n",
    "    n_est_dict_y_d[max_d] = y_pred_RF\n",
    "    print(\"RF Error:\", metrics.mean_squared_error(Y_test, y_pred_RF))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Hyperparameter Tuning\n",
    "\n",
    "Varying number of trees (n_estimators)\n",
    "\n",
    "n_estimators|min_sampels_leaf|MSE|\n",
    "---|---|---|\n",
    "40|10|43.69|\n",
    "80|10|43.69|\n",
    "120|10|43.79|\n",
    "160|10|43.46|\n",
    "200|10|43.75|\n",
    "\n",
    "\n",
    "Varying minimum number of samples per leaf node (n_estimators)\n",
    "\n",
    "n_estimators|min_sampels_leaf|MSE|\n",
    "---|---|---|\n",
    "40|10|43.70|\n",
    "40|12|43.83|\n",
    "40|14|42.69|\n",
    "40|16|41.94|\n",
    "40|18|43.46|\n",
    "40|20|42.43|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression modeling - Final modeling\n",
    "n_est = 160 #The number of trees in the forest.\n",
    "max_d = 16 #Max depth of the tree\n",
    "min_samples = 100 #The minimum number of samples required to be at a leaf node. \n",
    "\n",
    "m1 = RandomForestRegressor(n_estimators = n_est, max_depth = max_d, min_samples_leaf = min_samples)\n",
    "m1.fit(X_train,Y_train)\n",
    "y_pred_RF = m1.predict(X_test)\n",
    "print(\"RF Error:\", metrics.mean_squared_error(Y_test, y_pred_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join testing data: X_test, y_test, y_pred to a single dataframe for visualization\n",
    "y_vals = X_test.copy()\n",
    "y_vals['true_IS'], y_vals['pred_RF'], y_vals['pred_MLR'] = y_test, y_pred_RF, y_pred_MLR\n",
    "\n",
    "y_vals = y_vals.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a certain zip code data. i.e. lat = 47, long = -122\n",
    "zip_lat, zip_lon = 47, -122\n",
    "data_zip = y_vals[(y_vals['lat']==zip_lat) & (y_vals['lng']==zip_lon)]\n",
    "\n",
    "print(data_zip.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(15,5))\n",
    "ax.plot(data_zip['true_IS'], label = 'True Value')\n",
    "ax.plot(data_zip['pred_RF'], label = 'Random Forest')\n",
    "ax.plot(data_zip['pred_MLR'], label = 'Regression')\n",
    "ax.set(xlabel='Index', ylabel='Impact Score')\n",
    "ax.legend()\n",
    "fig.suptitle('lat '+str(zip_lat)+ ' & long ' + str(zip_lon), fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
