{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final imputation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use haversine formula to calculate shortest distance over the earth's surface\n",
    "# https://en.wikipedia.org/wiki/Haversine_formula\n",
    "\n",
    "def latlong_distance(lat1, long1, lat2, long2):\n",
    "    lat1 = np.radians(lat1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lat_delta = lat2 - lat1\n",
    "    long_delta = np.radians(long2 - long1)\n",
    "    #a = sin^2(latitude delta / 2) + cos latitude 1 * cos latitude 2\n",
    "    #* sin^2(longitude delta / 2)\n",
    "    a = np.sin(lat_delta / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(long_delta / 2) ** 2\n",
    "\n",
    "    #c = 2 * arcsin(a^0.5)\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    #d = R * c\n",
    "    R = 6371 #earth's radius = 6371km\n",
    "    d = R * c\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_n_search(latlong, latlongs, **kwargs):\n",
    "    # find n closest latlongs to the given coordinates and corresponding weights\n",
    "    # input = tuple of target coordinates, list of tuples [(lat, long)], n\n",
    "    # output = dict, key = weights, values = tuple(lat, long)\n",
    "    target_lat, target_long = latlong\n",
    "    min_latlong = tuple()\n",
    "    min_distance = float('inf')\n",
    "    dist = {}\n",
    "    \n",
    "    # evaluate each lat long pairs\n",
    "    for (lat, long) in latlongs:\n",
    "        # only evaluate lat long coordinates within a certain range\n",
    "        if np.abs(lat - target_lat) <= 10 and np.abs(long - target_long) <= 10:\n",
    "            dist = latlong_distance(target_lat, target_long, lat, long)\n",
    "\n",
    "            if len(min_latlong) < 1 or dist <= min_distance:\n",
    "                min_latlong = (lat, long)\n",
    "                min_distance = dist\n",
    "    return min_latlong, min_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('data_before_impute.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('full.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-calculate closest n neighbors and corresponding weights of all coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute n nearest neighbor based on distance\n",
    "#df = data\n",
    "\n",
    "# Select unique lat long combinations from the data\n",
    "latlongs = data[['grid_lat', 'grid_lon']].values\n",
    "latlongs = [(ll[0], ll[1]) for ll in latlongs]\n",
    "latlongs = list(set(latlongs))\n",
    "len(latlongs)\n",
    "\n",
    "latlong_matches = {}\n",
    "for i in range(len(latlongs)):\n",
    "    latlong_match = closest_n_search(latlongs[i], latlongs[:i] + latlongs[i + 1:])\n",
    "    latlong_matches[latlongs[i]] = latlong_match\n",
    "    # return dict\n",
    "    # key = (target_lat, target_long), value = (n_lat, n_long, dist)\n",
    "        \n",
    "print(\"example of coordinates at a similar distance to multiple points, target point :(36.0, -86.5), closest neighbor:\",\\\n",
    "latlong_matches[(36.0, -86.5)])\n",
    "\n",
    "dist_closest_n = [i[1] for i in list(latlong_matches.values())]\n",
    "\n",
    "print(f\"Average distance with geo-imputing ref (km): {np.mean(dist_closest_n)}\")\n",
    "print(f\"Min. distance with geo-imputing ref (km): {np.min(dist_closest_n)}\")\n",
    "print(f\"Max. distance with geo-imputing ref (km): {np.max(dist_closest_n)}\")\n",
    "\n",
    "#\"Distribution of distance to closest neighbor (km)\", plt.hist(dist_closest_n, bins=[0,100,200,300,400,500,600,700,800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(9, 5))\n",
    "ax = sns.distplot(dist_closest_n,bins=9,kde=False)\n",
    "ax.set(xlabel='Distance to closest FC (km)', ylabel='Count')\n",
    "fig.suptitle(\"Histogram of distance to closest neighbor of FCs\", fontsize=15)\n",
    "#plt.show()\n",
    "fig.savefig('Figure_3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize data to ensure there are data records for all dates, zip5 and time (4 times a day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    f = (data['date_key'] == row['date_key']) & (data['zip5'] == row['zip5'])\n",
    "    if pd.isna(row['Date']):\n",
    "        data.at[index,'Date'] = row['date_key']\n",
    "    if pd.isna(row['Time']):\n",
    "        missing_times = list(set(time) - set(data[f]['Time']))\n",
    "        data.at[index,'Time'] = missing_times[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns with > 80% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = [\"ForecastRange\",\"Categorical_Snow_surface\",\\\n",
    "                              \"Composite_reflectivity_entire_atmosphere\",\n",
    "                              \"Graupel_snow_pellets_hybrid\",\\\n",
    "                              \"Graupel_snow_pellets_isobaric\",\\\n",
    "                              \"Snow_mixing_ratio_hybrid\",\\\n",
    "                              \"Snow_mixing_ratio_isobaric\",\\\n",
    "                              'Geopotential_height_potential_vorticity_surface', \\\n",
    "                              'u_component_of_wind_potential_vorticity_surface',\\\n",
    "                              'v_component_of_wind_potential_vorticity_surface',\\\n",
    "                              'Categorical_Ice_Pellets_surface',\\\n",
    "                              'Ice_water_mixing_ratio_hybrid',\\\n",
    "                              'Ice_water_mixing_ratio_isobaric',\\\n",
    "                              'Precipitation_rate_surface',\\\n",
    "                              'Vertical_velocity_geometric_isobaric',\\\n",
    "                              'Ice_growth_rate_altitude_above_msl',\\\n",
    "                              'Land_sea_coverage_nearest_neighbor_land1sea0_surface',\\\n",
    "                              'Pressure_potential_vorticity_surface',\\\n",
    "                              'Temperature_potential_vorticity_surface',\\\n",
    "                              'Vertical_Speed_Shear_potential_vorticity_surface',\\\n",
    "                              'Rain_mixing_ratio_hybrid',\\\n",
    "                              'Total_cloud_cover_isobaric',\\\n",
    "                              'Cloud_mixing_ratio_hybrid',\\\n",
    "                              'Categorical_Freezing_Rain_surface',\\\n",
    "                              'Categorical_Rain_surface', 'Visibility_surface'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_impute(lat, long, date, time, colname, data):\n",
    "    n_latlong, dist = latlong_matches[(lat, long)]\n",
    "    #print('\\n=================')\n",
    "    #print(\"target point:\" , \"(\" ,lat,long, \"), closest neighbor:\", n_latlong, \", distance:\", dist)\n",
    "    b = data[(data['grid_lat'] == n_latlong[0]) & (data['grid_lon'] == n_latlong[1])\\\n",
    "        & (data['date_key'] == date) & (data['Time'] == time)]\n",
    "    #print('\\nData of closet neighbor\\n',b,'\\n')\n",
    "    #print(np.sum(b))\n",
    "    if b.shape[0] == 0:\n",
    "        output = np.nan\n",
    "    else: \n",
    "        output = b[colname].values[0]\n",
    "    #print('imputed value:', output, 'distance',dist)\n",
    "    #print('=================\\n')\n",
    "    return output, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for all features to impute\n",
    "\n",
    "cols_to_impute = ['Snow_depth_surface', 'Haines_Index_surface',\\\n",
    "'u_component_of_wind_altitude_above_msl', 'v_component_of_wind_altitude_above_msl',\\\n",
    "'Soil_temperature_depth_below_surface_layer', 'Temperature_altitude_above_msl',\\\n",
    "'Volumetric_Soil_Moisture_Content_depth_below_surface_layer', 'Field_Capacity_surface', \\\n",
    "'Water_equivalent_of_accumulated_snow_depth_surface', 'Wilting_Point_surface']\n",
    "\n",
    "#Find index of column to impute\n",
    "for colname in cols_to_impute:\n",
    "    #colname = cols_to_impute[0]\n",
    "    colind = list(data.columns).index(colname)\n",
    "    print('Impute for column', colname)\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        data_target = data.iloc[i,:]\n",
    "        #print(data_target)\n",
    "        if np.isnan(data_target[colname]): #If data is missing, we need to impute\n",
    "            print(i, '=>impute')\n",
    "            lat, long, date, time = data_target['grid_lat'], data_target['grid_lon'], data_target['date_key'], data_target['Time']\n",
    "            i_value, dist = spatial_impute(lat, long, date, time, colname, data)\n",
    "\n",
    "            #Sucessful spatial imputation is when the imputed value is non-nan and the distance to the closest neighbor is < 200\n",
    "            #The code currently set imputed value to Nan if the closest neighbor does not have value. \n",
    "            #However, it still returns a real value even when the distance to the closest neighbor is > 200. Code below is to fix it:\n",
    "            if dist > 200:\n",
    "                i_value = np.nan\n",
    "\n",
    "            #Put the imputed values and flags inside the original dataframe:\n",
    "            data.iloc[i,-3] = 1 #Update the column \"any_impute_col\" value to 1\n",
    "            data.iloc[i,colind] = i_value\n",
    "        #else:\n",
    "        #    print(i, '=> no impute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal Interpolation/ Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_hdf('imputeddata.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series interpolation\n",
    "pd.to_datetime(data['datetime'])\n",
    "data.set_index('datetime')\n",
    "data.head()\n",
    "data_interpolate = data.groupby(['grid_lat', 'grid_lon']).apply(lambda x: x.interpolate(method='linear', limit_direction = 'both'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
